{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/neQtZT8rNJYjgD9mjYFx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lblabucsd/Zada_Schulze_24/blob/main/data_processing_utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "latest update: MattLB. July24, 2023\n",
        "\n",
        "*note: changed errors in occupancy map calculations"
      ],
      "metadata": {
        "id": "9cwf1CkPqDpy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Package import and some helpful function"
      ],
      "metadata": {
        "id": "JsXT_xAhhtRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # import python packages, important to keep in this enviornment\n",
        "# from google.colab import auth\n",
        "# auth.authenticate_user()\n",
        "import gspread\n",
        "from google.auth import default\n",
        "\n",
        "# from ast import Expression\n",
        "# import csv\n",
        "import h5py\n",
        "# import json\n",
        "import math\n",
        "# import matplotlib as mpl\n",
        "# from matplotlib import pyplot as plt\n",
        "# from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "# import matplotlib.animation as animation\n",
        "# %matplotlib inline\n",
        "import numpy as np\n",
        "import os\n",
        "# from os import path\n",
        "import pandas as pd\n",
        "# from pandas.core.ops.array_ops import expressions\n",
        "# import scipy\n",
        "from scipy.interpolate import interp1d\n",
        "from scipy.spatial import ConvexHull\n",
        "# from scipy import ndimage, io, signal, interpolate\n",
        "# import seaborn as sns\n",
        "# import sklearn\n",
        "# from sklearn.decomposition import PCA\n",
        "from skimage.transform import resize\n",
        "# from skimage import io, filters, feature, morphology, util\n",
        "# import statsmodels\n",
        "# import subprocess\n",
        "# import time\n",
        "# import tqdm\n",
        "# import random\n",
        "# from random import randrange, shuffle\n",
        "# sns.set_style(\"white\")"
      ],
      "metadata": {
        "id": "xVLzY9RfOd3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# basic processing\n",
        "def fill_missing(Y, kind=\"linear\"):\n",
        "    \"\"\"Fills missing values independently along each dimension after the first.\n",
        "    Args:\n",
        "      Y: array like object\n",
        "      kind: 'linear', refer to scipy.interpolate.interp1d for more options\n",
        "    Returns:\n",
        "      np.array\n",
        "    \"\"\"\n",
        "    # Store initial shape.\n",
        "    initial_shape = Y.shape\n",
        "    # Flatten after first dim.\n",
        "    Y = Y.reshape((initial_shape[0], -1))\n",
        "    # Interpolate along each slice.\n",
        "    for i in range(Y.shape[-1]):\n",
        "        y = Y[:, i]\n",
        "        # Build interpolant.\n",
        "        x = np.flatnonzero(~np.isnan(y))\n",
        "        f = interp1d(x, y[x], kind=kind, fill_value=np.nan, bounds_error=False)\n",
        "        # Fill missing\n",
        "        xq = np.flatnonzero(np.isnan(y))\n",
        "        y[xq] = f(xq)\n",
        "        # Fill leading or trailing NaNs with the nearest non-NaN values\n",
        "        mask = np.isnan(y)\n",
        "        y[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), y[~mask])\n",
        "        # Save slice\n",
        "        Y[:, i] = y\n",
        "    # Restore to initial shape.\n",
        "    Y = Y.reshape(initial_shape)\n",
        "    return Y"
      ],
      "metadata": {
        "id": "OllfUOeELBx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def running_mean(x, N):\n",
        "    return np.convolve(x, np.ones(N)/N, mode='same')\n",
        "\n",
        "def normalize_array(inputs):\n",
        "    output = (inputs-min(inputs))/(max(inputs)-min(inputs))\n",
        "    return output"
      ],
      "metadata": {
        "id": "I7rnMW_n5uGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def speed_angular_sp(x,y,heading,body_length,frame_rate,scale):\n",
        "  \"\"\" Swimming kinematics of given xy positions over time\n",
        "  Args:\n",
        "    x, y (float): arrays of xy coordinates in pixel\n",
        "    heading (float): arrays of heading direction in degree\n",
        "    scale (float): value of mm per pixel in experiment video\n",
        "    body_length (float): arrays of each fish body\n",
        "    frame_rate (float): video frame rate in Hz\n",
        "  Returns:\n",
        "    speed: array of speed and angular speed in px/sec\n",
        "    angular speed: array of angular speed in dg/sec\n",
        "  \"\"\"\n",
        "  max_speed = 20*body_length # per second\n",
        "  max_ang_speed = 720 # per second\n",
        "\n",
        "  # use position difference across 2 inter-frame intervals\n",
        "  dx = x.flat[2:] - x.flat[:-2]\n",
        "  dx = np.pad(dx, (1, 1), 'constant', constant_values=(0, 0)) # pad 0 to both ends\n",
        "  dy = y.flat[2:] - y.flat[:-2]\n",
        "  dy = np.pad(dy, (1, 1), 'constant', constant_values=(0, 0)) # pad 0 to both ends\n",
        "  sp = np.sqrt(dx**2+dy**2)/scale*(frame_rate/2)\n",
        "  sp_filt = np.where(sp > max_speed, np.nan, sp)\n",
        "  speed = fill_missing(sp_filt)\n",
        "\n",
        "  # use orientation difference between two consecutive frames\n",
        "  dag = np.ediff1d(heading, to_begin=0)\n",
        "  asp=np.array([((d+180)%360 - 180)*frame_rate for d in dag])\n",
        "  asp_filt = np.where(abs(asp) > max_ang_speed, np.nan, asp)\n",
        "  ang_speed = fill_missing(asp_filt)\n",
        "\n",
        "  return speed, ang_speed\n",
        "\n",
        "\n",
        "def speed_calc(f_x,f_y,f_head_angle,body_length,frame_rate,scale):\n",
        "\n",
        "  max_speed = 20*body_length # per second\n",
        "  max_ang_speed = 360 # per second\n",
        "\n",
        "  time = [float(i/frame_rate) for i in range(len(f_x))]\n",
        "\n",
        "  speed = []\n",
        "  ang_speed = []\n",
        "  for ndx,t in enumerate(time):\n",
        "      sp = math.dist([f_x[ndx],f_y[ndx]],[f_x[ndx-1],f_y[ndx-1]])/(time[ndx]-time[ndx-1])\n",
        "      asp = (((f_head_angle[ndx]-f_head_angle[ndx-1]) + 180) % 360-180)/(time[ndx]-time[ndx-1])\n",
        "      if sp < max_speed:\n",
        "        speed.append(sp)\n",
        "      else:\n",
        "        speed.append(speed[-1])\n",
        "\n",
        "      if abs(asp) < max_ang_speed:\n",
        "        ang_speed.append(asp)\n",
        "      else:\n",
        "        ang_speed.append(ang_speed[-1])\n",
        "\n",
        "  return speed, ang_speed\n",
        "\n",
        "\n",
        "#calculate angles between 2 points\n",
        "def calculate_angle(X1,Y1,X2,Y2):\n",
        "    rads=[];\n",
        "    for x1,y1,x2,y2 in zip(X1,Y1,X2,Y2):\n",
        "        dx=x1-x2\n",
        "        dy=y1-y2\n",
        "        rads.append(math.atan2(dy, dx))\n",
        "    degs = np.rad2deg(rads)\n",
        "    return degs\n",
        "\n",
        "def get_single_angle(x1,y1,x2,y2):\n",
        "    return math.degrees(math.atan2(y2-y1, x2-x1))"
      ],
      "metadata": {
        "id": "uoufPspp6Umz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pt_rotate(x, y, deg, self_x, self_y):\n",
        "    \"\"\"Rotate a point around a given point.\n",
        "    Args:\n",
        "      x, y: arrays of xy coordinates that need to rotate\n",
        "      self_x, self_y: arrays of xy coordinates that serve as reference point\n",
        "      deg: orientation angle of the reference point\n",
        "    Returns:\n",
        "      qx, qy: new xy coordinates when reference point is at (0,0) facing north\n",
        "    \"\"\"\n",
        "    qx = self_x + math.cos(np.deg2rad(deg))*(x-self_x) + math.sin(np.deg2rad(deg))*(y-self_y)\n",
        "    qy = self_y - math.sin(np.deg2rad(deg))*(x-self_x) + math.cos(np.deg2rad(deg))*(y-self_y)\n",
        "\n",
        "\n",
        "    return qx, qy"
      ],
      "metadata": {
        "id": "2RGMUYk_wPU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Meta)Data reading and Level 0 processing"
      ],
      "metadata": {
        "id": "LpxrKpsRhoNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_metadata(gsheet_url,tab_name):\n",
        "  \"\"\"This script reads information in a tab in the Google sheet, where metadata for each experiment is stored.\n",
        "  \"\"\"\n",
        "  # import gspread\n",
        "  # from google.auth import default\n",
        "\n",
        "  # reading in google sheet with experimental details\n",
        "  creds, _ = default()\n",
        "  gc = gspread.authorize(creds)\n",
        "\n",
        "  # insert URl of gsheet, specify worksheets as different variables\n",
        "  wb = gc.open_by_url(gsheet_url)\n",
        "  exps = wb.worksheet(tab_name)\n",
        "\n",
        "  #\n",
        "  all_data = pd.DataFrame(exps.get_all_records())\n",
        "  metadata = all_data.set_index('experiment')\n",
        "  display(all_data)\n",
        "\n",
        "  return metadata"
      ],
      "metadata": {
        "id": "eLxRk_U7fKx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZHrFV8WNm5c"
      },
      "outputs": [],
      "source": [
        "class Fish():\n",
        "  \"\"\"Collect individual fish tracking info for easier  data call in pipeline.\n",
        "  \"\"\"\n",
        "  pass\n",
        "\n",
        "def process_h5(h5tracks,fish_num,sleap_nodes,exp):\n",
        "  \"\"\"This script reads xy info of each body node of individual fish in a group.\n",
        "  Return: list of objects with attributes of xy coordinates.\n",
        "  \"\"\"\n",
        "  frame_num, _, _, track_num = h5tracks.shape\n",
        "  group_data = []\n",
        "  for f in range(fish_num):\n",
        "\n",
        "    name = exp + '_f'+ str(f+1)\n",
        "    fish = Fish() # make class object\n",
        "    setattr(fish,'name',name)\n",
        "\n",
        "    # load all xy coordinates\n",
        "    for idx, node in enumerate(sleap_nodes):\n",
        "      setattr(fish,str(node)+'x',fill_missing(h5tracks[:,idx,0,f]))\n",
        "      setattr(fish,str(node)+'y',fill_missing(h5tracks[:,idx,1,f]))\n",
        "    group_data.append(fish)\n",
        "\n",
        "  return group_data\n",
        "\n",
        "def process_h5_single_animal(h5tracks,sleap_nodes):\n",
        "  \"\"\"This script reads xy info of each body node for a single animal and return them into 2 arrays (length = frame_num).\n",
        "  \"\"\"\n",
        "  frame_num, _, _, track_num = h5tracks.shape\n",
        "  fish_data_x = np.empty((frame_num))\n",
        "  fish_data_y = np.empty((frame_num))\n",
        "\n",
        "  for f in range(track_num):\n",
        "\n",
        "    for idx, node in enumerate(sleap_nodes):\n",
        "      fish_data_x[idx] = fill_missing(h5tracks[:,idx,0,f])\n",
        "      fish_data_y[idx] = fill_missing(h5tracks[:,idx,1,f])\n",
        "\n",
        "  return fish_data_x,fish_data_y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def group_arrays(group_data,fish_num,frame_num,frame_rate,scale):\n",
        "  \"\"\"This script takes the processed h5 data and stacks them into group arrays shaped in fish_num x frame_num.\n",
        "  \"\"\"\n",
        "  # initialize group arrays\n",
        "  f_bodylength_mm = [[] for f in range(fish_num)]\n",
        "  f_bodylength_px = [[] for f in range(fish_num)]\n",
        "\n",
        "  # postional\n",
        "  f_nosex = [[] for f in range(fish_num)]; f_nosey = [[] for f in range(fish_num)] # center of two eyes\n",
        "  f_x = [[] for f in range(fish_num)]; f_y = [[] for f in range(fish_num)] # front bladder or belly as the centroid\n",
        "  f_tailx = [[] for f in range(fish_num)]; f_taily = [[] for f in range(fish_num)] # tip of the tail\n",
        "  # angular\n",
        "  f_heading = [[] for f in range(fish_num)]; f_tail_angle = [[] for f in range(fish_num)]\n",
        "  # speed stuff\n",
        "  f_speed = [[] for f in range(fish_num)]; f_ang_speed = [[] for f in range(fish_num)]\n",
        "\n",
        "  # set window size (num of frame) for running mean\n",
        "  pos_ker = 5 # for positional data\n",
        "  ang_ker = 5 # for angular data\n",
        "  spd_ker = 10 # for speed data\n",
        "\n",
        "  # loop through the individual fish\n",
        "  for ndx, fish in enumerate(group_data):\n",
        "\n",
        "    # get ind nose - centr of two eyes\n",
        "    nosex = [int(np.mean([l,r])) for l,r in zip(fish.lex,fish.rex)]\n",
        "    nosey = [int(np.mean([l,r])) for l,r in zip(fish.ley,fish.rey)]\n",
        "\n",
        "    # get ind fish body length - 95th percentil across the frames\n",
        "    nose_to_tail = np.sqrt( (nosex - fish.ttx)**2 + (nosey - fish.tty)**2 )\n",
        "    bodylen_px =  np.percentile(nose_to_tail,99)\n",
        "    bodylen_mm =  np.percentile(nose_to_tail,99)*scale\n",
        "\n",
        "    # stack the convolved arrays\n",
        "    f_bodylength_px[ndx] = bodylen_px\n",
        "    f_bodylength_mm[ndx] = bodylen_mm\n",
        "\n",
        "    f_nosex[ndx] = running_mean(nosex,pos_ker)\n",
        "    f_nosey[ndx] = running_mean(nosey,pos_ker)\n",
        "    #f_x[ndx] = running_mean(fish.mbx,pos_ker) #if jy nodes\n",
        "    #f_y[ndx] = running_mean(fish.mby,pos_ker) #if jy nodes\n",
        "    f_x[ndx] = running_mean(fish.byx,pos_ker) #if dz nodes\n",
        "    f_y[ndx] = running_mean(fish.byy,pos_ker) #if dz nodes\n",
        "    f_tailx[ndx] = running_mean(fish.ttx,pos_ker)\n",
        "    f_taily[ndx] = running_mean(fish.tty,pos_ker)\n",
        "\n",
        "    # get ind fish orientation and tail angle per frame\n",
        "    heading = calculate_angle(f_nosex[ndx],f_nosey[ndx],f_x[ndx],f_y[ndx])\n",
        "    tail = calculate_angle(f_x[ndx],f_y[ndx],f_tailx[ndx],f_taily[ndx])\n",
        "\n",
        "    f_heading[ndx] = running_mean(heading, ang_ker)\n",
        "    f_tail_angle[ndx] = running_mean((( (tail-heading) + 180) % 360) - 180, ang_ker)\n",
        "\n",
        "    # get ind fish speed and angular speed per frame\n",
        "    #speed, angular_speed = speed_angular_sp(fish.mbx,fish.mby,heading,bodylen_px,frame_rate,scale) #if jy nodes\n",
        "    speed, angular_speed = speed_angular_sp(fish.byx,fish.byy,heading,bodylen_px,frame_rate,scale) #if dz nodes\n",
        "\n",
        "\n",
        "    f_speed[ndx] = running_mean(speed, spd_ker)\n",
        "    f_ang_speed[ndx] = running_mean(angular_speed, spd_ker)\n",
        "\n",
        "\n",
        "\n",
        "  return f_bodylength_px, f_bodylength_mm, f_nosex, f_nosey, f_x, f_y, f_tailx, f_taily, f_heading, f_tail_angle, f_speed, f_ang_speed"
      ],
      "metadata": {
        "id": "6-kXR1WoCu5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_neighbors(fish_num,f_heading,f_x,f_y,frame_num,scale,f_body_length):\n",
        "  \"\"\"This script generates group arrays of distance and alignment between individual fish and their neighbors.\n",
        "  \"\"\"\n",
        "\n",
        "  if fish_num == 2:\n",
        "\n",
        "    # initialize arrays\n",
        "    ff_dist = np.zeros((fish_num,fish_num-1,frame_num))\n",
        "    ff_align = np.zeros((fish_num,fish_num-1,frame_num))\n",
        "    f_closest_id = np.zeros((fish_num,frame_num))\n",
        "    f_closest_dist = np.zeros((fish_num,frame_num))\n",
        "    f_closest_align = np.zeros((fish_num,frame_num))\n",
        "\n",
        "    for f0 in range(fish_num):\n",
        "      for f1 in range(fish_num):\n",
        "        if f1 != f0:\n",
        "          dist = np.abs(np.sqrt( (f_x[f0]-f_x[f1])**2 + (f_y[f0]-f_y[f1])**2 ) )*scale\n",
        "          align = ((( f_heading[f0]-f_heading[f1] ) + 180) % 360 - 180)\n",
        "\n",
        "          ff_dist[f0][0] = dist\n",
        "          ff_align[f0][0] = align\n",
        "\n",
        "    f_IID = ff_dist[0]\n",
        "    f_IIA = ff_align[0]\n",
        "    #\n",
        "    f_closest_id = np.stack( (np.ones((frame_num)), np.zeros((frame_num))) )\n",
        "    f_closest_dist = ff_dist\n",
        "    f_closest_align = ff_align\n",
        "\n",
        "\n",
        "  else: # if fish_num >= 3\n",
        "\n",
        "    # initialize arrays and lists\n",
        "    ff_dist = np.zeros((fish_num,fish_num-1,frame_num))\n",
        "    ff_align = np.zeros((fish_num,fish_num-1,frame_num))\n",
        "    f_IID = []; f_IIA = [] # number of dyads x framenum\n",
        "    f_closest_id = np.zeros((fish_num,frame_num))\n",
        "    f_closest_dist = np.zeros((fish_num,frame_num))\n",
        "    f_closest_align = np.zeros((fish_num,frame_num))\n",
        "\n",
        "    # loop through ind fish\n",
        "    for f0 in range(fish_num):\n",
        "      nb_count = 0\n",
        "\n",
        "      for f1 in range(fish_num):\n",
        "        if f1 != f0:\n",
        "          nb_count += 1\n",
        "\n",
        "          dist = np.abs(np.sqrt( (f_x[f0]-f_x[f1])**2 + (f_y[f0]-f_y[f1])**2 ) )*scale\n",
        "          align = ((( f_heading[f0]-f_heading[f1] ) + 180) % 360 - 180)\n",
        "\n",
        "          ff_dist[f0][nb_count-1] = dist\n",
        "          ff_align[f0][nb_count-1] = align\n",
        "\n",
        "\n",
        "        if f0 < f1:\n",
        "          f_IID.append(dist)\n",
        "          f_IIA.append(align)\n",
        "\n",
        "    f_IID = np.array(f_IID)\n",
        "    f_IIA = np.array(f_IIA)\n",
        "\n",
        "    # find the stats with the closest neighbor for each fish\n",
        "    for f0 in range(fish_num):\n",
        "      closest_dist = np.array(np.min(ff_dist[f0],axis=0)) # find the smallest dist in each frame\n",
        "      f_closest_id[f0] = np.argmin(ff_dist[f0] == closest_dist, axis=0) # identify which fish it is\n",
        "      index = f_closest_id[f0].astype(int)\n",
        "      f_closest_dist[f0] = closest_dist # find their distance\n",
        "      f_closest_align[f0] = ff_align[f0][index,np.arange(len(index))] # find their alignment\n",
        "\n",
        "  return ff_dist, ff_align, f_IID, f_IIA, f_closest_id, f_closest_dist, f_closest_align"
      ],
      "metadata": {
        "id": "R3yDRgajOrAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_npz(save_path,experiment,filename,savinglist):\n",
        "  \"\"\"This script saves processed data into npz (1 npz per experiment recording).\n",
        "  Args: savinglist (dictionary with name and values of each numpy array)\n",
        "  \"\"\"\n",
        "  os.makedirs(save_path + experiment, exist_ok=True)\n",
        "\n",
        "  # initizlize a dictionary for variables to save\n",
        "  savez_dict = dict()\n",
        "\n",
        "  # fill in the dictionary with variable names + values\n",
        "  for key, value in savinglist.items():\n",
        "    savez_dict[str(key)] = value\n",
        "\n",
        "  # save npz\n",
        "  np.savez(save_path + experiment + '/' + experiment + '_' + filename +'.npz', **savez_dict)"
      ],
      "metadata": {
        "id": "lwTheFc1arPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Level 1 processing"
      ],
      "metadata": {
        "id": "dwYnbkv2WlBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def egocentric_occupancy(fish_num,f_x,f_y,f_heading,f_speed,f_ang_speed,start,stop,imsize,subsize,sample):\n",
        "  \"\"\"This scripts generates egocentric occupancy matrices for each fish.\n",
        "  Returns:\n",
        "    3D arrays (fish_num,frames,(subsize,subsize))\n",
        "  \"\"\"\n",
        "  sample = sample # sampling rate - take every Nth frames\n",
        "  offset = int(imsize/2) # max distance of neighbor position from foca fish to be include\n",
        "  frame_num = len(f_y[0][start:stop:sample]) #number of timepoints\n",
        "\n",
        "  # initialize empty 3D matrix (fishnum,framenum,imsize,imsize)\n",
        "\n",
        "  __occupancy_maps=[]\n",
        "\n",
        "  # for each focal fish\n",
        "  for f0 in range(fish_num):\n",
        "\n",
        "    omap=np.zeros([frame_num,imsize,imsize])\n",
        "\n",
        "    # loop through each neighbor\n",
        "    for f1 in range(fish_num):\n",
        "      if f1 != f0:\n",
        "\n",
        "        # sample the focal fish data\n",
        "        x_0, y_0 = f_x[f0][start:stop:sample], f_y[f0][start:stop:sample]\n",
        "        heading_0 = f_heading[f0][start:stop:sample]\n",
        "\n",
        "        # sample the neighbor fish data\n",
        "        x_1,y_1 = f_x[f1][start:stop:sample],f_y[f1][start:stop:sample]\n",
        "        heading_1 = f_heading[f1][start:stop:sample]\n",
        "\n",
        "        # go through each observation\n",
        "        for ndx,(d0,d1,x0,x1,y0,y1) in enumerate(zip(heading_0,heading_1,x_0,x_1,y_0,y_1)):\n",
        "\n",
        "          # rotate the neighbor fish position and heading based on focal fish\n",
        "          x1_rot, y1_rot = pt_rotate(x1, y1, d0, x0, y0)\n",
        "          #of other fish within region, add to map\n",
        "          if abs(x0-x1_rot)<offset and abs(y0-y1_rot)<offset:\n",
        "            #add in condition that fish is not at extremes of dish\n",
        "            omap[ndx,int(x0-x1_rot)+offset,int(y0-y1_rot)+offset]=1\n",
        "\n",
        "  __occupancy_maps.append(omap)\n",
        "  del(omap)\n",
        "\n",
        "  #Merge across fish and resize, for each timepoint\n",
        "  f_occupancy_maps = np.array([resize(M,(subsize,subsize)) for M in np.sum(__occupancy_maps, axis=0)])\n",
        "\n",
        "  return f_occupancy_maps\n",
        "\n",
        "\n",
        "def egocentric_alignment(fish_num,f_x,f_y,f_heading,f_speed,f_ang_speed,start,stop,imsize,subsize,sample):\n",
        "  \"\"\"This scripts generates egocentric alignment probability matrices for each fish.\n",
        "  Returns:\n",
        "    3D arrays (fish_num,frames,(subsize,subsize))\n",
        "  \"\"\"\n",
        "  sample = sample # sampling rate - take every Nth frames\n",
        "  offset = int(imsize/2) # max distance of neighbor position from foca fish to be include\n",
        "  frame_num = len(f_y[0][start:stop:sample]) #number of timepoints\n",
        "\n",
        "  __alignment_maps=[]\n",
        "\n",
        "  # for each focal fish\n",
        "  for f0 in range(fish_num):\n",
        "\n",
        "    amap=np.full([frame_num,imsize,imsize], 180)\n",
        "\n",
        "    # loop through each neighbor\n",
        "    for f1 in range(fish_num):\n",
        "      if f1 != f0:\n",
        "\n",
        "        # sample the focal fish data\n",
        "        x_0, y_0 = f_x[f0][start:stop:sample], f_y[f0][start:stop:sample]\n",
        "        heading_0 = f_heading[f0][start:stop:sample]\n",
        "\n",
        "        # sample the neighbor fish data\n",
        "        x_1,y_1 = f_x[f1][start:stop:sample],f_y[f1][start:stop:sample]\n",
        "        heading_1 = f_heading[f1][start:stop:sample]\n",
        "\n",
        "        # go through each observation\n",
        "        for ndx,(d0,d1,x0,x1,y0,y1) in enumerate(zip(heading_0,heading_1,x_0,x_1,y_0,y_1)):\n",
        "\n",
        "          # rotate the neighbor fish position and heading based on focal fish\n",
        "          x1_rot, y1_rot = pt_rotate(x1, y1, d0, x0, y0)\n",
        "          #of other fish within region, add to map\n",
        "          if abs(x0-x1_rot)<offset and abs(y0-y1_rot)<offset:\n",
        "            amap[ndx,int(x0-x1_rot)+offset,int(y0-y1_rot)+offset]=abs(((d1-d0) + 180) % 360-180)\n",
        "\n",
        "  __alignment_maps.append(amap)\n",
        "  del(amap)\n",
        "\n",
        "  #Merge across fish and resize, for each timepoint\n",
        "  f_alignment_maps = np.array([resize(M,(subsize,subsize)) for M in np.mean(__alignment_maps, axis=0)])\n",
        "\n",
        "  return f_alignment_maps\n",
        "\n",
        "\n",
        "\n",
        "def egocentric_speed(fish_num,f_x,f_y,f_heading,f_speed,f_ang_speed,start,stop,imsize,subsize,sample):\n",
        "  \"\"\"This scripts generates egocentric speed matrices for each fish.\n",
        "  Returns:\n",
        "    3D arrays (fish_num,frames,(subsize,subsize))\n",
        "  \"\"\"\n",
        "  sample = sample # sampling rate - take every Nth frames\n",
        "  offset = int(imsize/2) # max distance of neighbor position from foca fish to be include\n",
        "  frame_num = len(f_y[0][start:stop:sample]) #number of timepoints\n",
        "\n",
        "  f_speed_maps=[[] for n in range(fish_num)]\n",
        "  f_ang_speed_maps=[[] for n in range(fish_num)]\n",
        "\n",
        "  #for each moment in time:\n",
        "  frames = range(len(f_x[0][start:stop:sample]))\n",
        "\n",
        "  for frame_index in frames:\n",
        "    #for each focal fish\n",
        "    for f0 in range(fish_num):\n",
        "      x0, y0 = f_x[f0][frame_index], f_y[f0][frame_index]\n",
        "      d0 = f_heading[f0][frame_index]\n",
        "      speed_0,ang_sp_0 = f_speed[f0][frame_index],f_ang_speed[f0][frame_index]\n",
        "\n",
        "      tmp_s=np.zeros([imsize,imsize])\n",
        "      tmp_as=np.zeros([imsize,imsize])\n",
        "\n",
        "      #for each neighbor\n",
        "      for f1 in range(fish_num):\n",
        "        if f1 != f0:\n",
        "          x1,y1 = f_x[f1][frame_index],f_y[f1][frame_index]\n",
        "          #place neighbor in eogentric position\n",
        "          a,b = pt_rotate(x1,y1,d0,x0,y0)\n",
        "\n",
        "          if abs(x0-a)<offset and abs(y0-b)<offset:\n",
        "            #append speed to map\n",
        "            tmp_s[int(x0-a)+offset,int(y0-b)+offset]=speed_0\n",
        "            tmp_as[int(x0-a)+offset,int(y0-b)+offset]=ang_sp_0\n",
        "\n",
        "      f_speed_maps[f0].append(resize(tmp_s,(subsize,subsize)))\n",
        "      f_ang_speed_maps[f0].append(resize(tmp_as,(subsize,subsize)))\n",
        "\n",
        "  return f_speed_maps, f_ang_speed_maps"
      ],
      "metadata": {
        "id": "No4j6L_AQaTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fish_polygon_area(xs,ys):\n",
        "    \"\"\"Calculate the area of a polygon given its vertices.\"\"\"\n",
        "    xs=np.array(xs).T\n",
        "    ys=np.array(ys).T\n",
        "    areas=[]\n",
        "    for f_x,f_y in zip(xs,ys):\n",
        "      points=[[x,y] for x,y in zip(f_x,f_y)]\n",
        "      hull=ConvexHull(np.array(points))\n",
        "      areas.append(hull.area)\n",
        "\n",
        "    return areas"
      ],
      "metadata": {
        "id": "z4qJFPZa0Zze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Level 2 processing"
      ],
      "metadata": {
        "id": "vBNrSGdkWovB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_visual_fields(fish_num,f_x,f_y,f_heading,f_bodylength,start,stop,scale,sample):\n",
        "\n",
        "  occupied_angles=[]\n",
        "\n",
        "  # for each focal fish\n",
        "  for f0 in range(fish_num):\n",
        "    fish_tmp = []\n",
        "    # loop through each neighbor\n",
        "    for f1 in range(fish_num):\n",
        "      if f1 != f0:\n",
        "        tmp=[]\n",
        "\n",
        "        #fish details\n",
        "        x_0, y_0 = f_x[f0][start:stop:sample], f_y[f0][start:stop:sample]\n",
        "        heading_0 = f_heading[f0][start:stop:sample]\n",
        "        x_1, y_1 = f_x[f1][start:stop:sample], f_y[f1][start:stop:sample]\n",
        "        heading_1 = f_heading[f1][start:stop:sample]\n",
        "        bodylength_1 = f_bodylength/scale\n",
        "\n",
        "        for ndx,(d0,d1,x0,x1,y0,y1) in enumerate(zip(heading_0,heading_1,x_0,x_1,y_0,y_1)):\n",
        "            x1_rot, y1_rot = pt_rotate(x1, y1, d0, x0, y0)\n",
        "\n",
        "            # Calculate the position of the endpoints of the line\n",
        "            endpoint1_x = x1_rot + bodylength_1/2.0 * np.cos(d1)\n",
        "            endpoint1_y = y1_rot + bodylength_1/2.0 * np.sin(d1)\n",
        "\n",
        "            endpoint2_x = x1_rot - bodylength_1/2.0 * np.cos(d1)\n",
        "            endpoint2_y = y1_rot - bodylength_1/2.0 * np.sin(d1)\n",
        "\n",
        "            angle1 = np.arctan2(endpoint1_y, endpoint1_x)\n",
        "            angle2 = np.arctan2(endpoint2_y, endpoint2_x)\n",
        "\n",
        "            tmp.append([min(angle1, angle2), max(angle1, angle2)])\n",
        "\n",
        "        fish_tmp.append(tmp)\n",
        "        del(tmp)\n",
        "    occupied_angles.append(fish_tmp)\n",
        "    del(fish_tmp)\n",
        "\n",
        "  return occupied_angles\n"
      ],
      "metadata": {
        "id": "sYaxjFFHdBTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dTN7G-NfWo9Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}